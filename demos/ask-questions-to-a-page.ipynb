{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazer perguntas a uma página da web\n",
    "\n",
    "Este é um pipeline muito simples que pode responder perguntas sobre o conteúdo de uma página web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalação do Haystack\n",
    "\n",
    "Primeiro, instale o Haystack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: haystack-ai in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: requests in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (2.31.0)\n",
      "Requirement already satisfied: pandas in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: lazy-imports in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (0.3.1)\n",
      "Requirement already satisfied: numpy in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (1.26.4)\n",
      "Requirement already satisfied: haystack-bm25 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (1.0.2)\n",
      "Requirement already satisfied: posthog in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (4.10.0)\n",
      "Requirement already satisfied: tenacity in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (8.2.3)\n",
      "Requirement already satisfied: networkx in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (3.2.1)\n",
      "Requirement already satisfied: pyyaml in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (6.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (1.13.3)\n",
      "Requirement already satisfied: boilerpy3 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (1.0.7)\n",
      "Requirement already satisfied: tqdm in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (4.66.2)\n",
      "Requirement already satisfied: more-itertools in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from haystack-ai) (10.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from openai>=1.1.0->haystack-ai) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from jinja2->haystack-ai) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from pandas->haystack-ai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from pandas->haystack-ai) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from python-dateutil->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from posthog->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from posthog->haystack-ai) (1.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from requests->haystack-ai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from requests->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from requests->haystack-ai) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from requests->haystack-ai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/tanabe/tech4humans/iag-labs-haystack/venv/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->haystack-ai) (2.16.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install haystack-ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Abordagens para usar o Haystack (Simplicidade vs. Flexibilidade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplicidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você pode instalar o Haystack utilizando o comando 'pip install haystack-ai'. Certifique-se de ter o Python e o pip instalados em seu ambiente antes de executar este comando.\"\n"
     ]
    }
   ],
   "source": [
    "# SIMPLICIDADE\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline, PredefinedPipeline\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "pipeline = Pipeline.from_template(PredefinedPipeline.CHAT_WITH_WEBSITE)\n",
    "result = pipeline.run({\n",
    "    \"fetcher\": {\"urls\": [\"https://haystack.deepset.ai/overview/quick-start\"]},\n",
    "    \"prompt\": {\"query\": \"Responda em português, como eu posso instalar o Haystack?\"}}\n",
    ")\n",
    "print(result[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexibilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para construir seu primeiro pipeline RAG com o Haystack, você precisa de três componentes principais: um Retriever, um PromptBuilder e um Generator. Você pode conectar esses componentes para criar um pipeline de Recuperação com Geração Aprimorada (RAG) que permitirá que você faça perguntas sobre documentos e obtenha respostas baseadas em modelos de linguagem. Siga as instruções fornecidas acima para instalar o Haystack, indexar seus documentos e executar consultas usando a abordagem RAG.\n"
     ]
    }
   ],
   "source": [
    "# FLEXIBILIDADE\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from haystack import Pipeline\n",
    "from haystack.components.fetchers import LinkContentFetcher\n",
    "from haystack.components.converters import HTMLToDocument\n",
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "fetcher = LinkContentFetcher()\n",
    "converter = HTMLToDocument()\n",
    "prompt_template = \"\"\"\n",
    "According to the contents of this website:\n",
    "{% for document in documents %}\n",
    "  {{document.content}}\n",
    "{% endfor %}\n",
    "Answer the given question: {{query}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "llm = OpenAIGenerator()\n",
    "\n",
    "pipeline = Pipeline()\n",
    "pipeline.add_component(\"fetcher\", fetcher)\n",
    "pipeline.add_component(\"converter\", converter)\n",
    "pipeline.add_component(\"prompt\", prompt_builder)\n",
    "pipeline.add_component(\"llm\", llm)\n",
    "\n",
    "pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
    "pipeline.connect(\"converter.documents\", \"prompt.documents\")\n",
    "pipeline.connect(\"prompt.prompt\", \"llm.prompt\")\n",
    "\n",
    "result = pipeline.run({\"fetcher\": {\"urls\": [\"https://haystack.deepset.ai/overview/quick-start\"]},\n",
    "              \"prompt\": {\"query\": \"Responda em português, como posso construir meu primeiro pipeline RAG?\"}})\n",
    "\n",
    "print(result[\"llm\"][\"replies\"][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fluxograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"../data/docs-data/overview/faca-perguntas-a-uma-pagina-da-web.png\" alt=\"Faça perguntas a uma página da web\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dois códigos demonstram diferentes maneiras de usar o framework Haystack para processar informações de páginas da web e gerar respostas baseadas nessas informações. Eles têm algumas diferenças fundamentais na abordagem e na complexidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplicidade (Código 1): Uso de PredefinedPipeline\n",
    "\n",
    "- **Simplicidade**: Este código utiliza a classe PredefinedPipeline para criar uma pipeline pré-definida com o mínimo de configuração necessária. Ele é mais direto e fácil de usar para casos de uso comuns.\n",
    "- **Configuração de Pipeline**: A pipeline é criada com o método from_template(), usando uma pipeline pré-definida (CHAT_WITH_WEBSITE). Isso significa que a estrutura da pipeline (fetching, conversão, geração) já está definida pela template, e o usuário não precisa configurar manualmente cada componente.\n",
    "- **Foco**: Este código é focado em extrair informações de URLs específicas para responder a uma pergunta, sem a necessidade de detalhar cada etapa do processo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexibilidade (Código 2): Construção Manual da Pipeline\n",
    "\n",
    "- **Flexibilidade**: Este código demonstra uma abordagem mais granular e flexível, construindo a pipeline componente por componente. Isso permite uma personalização mais detalhada de cada etapa do processo.\n",
    "- **Componentes Personalizados**: Aqui, os componentes são explicitamente criados e adicionados à pipeline (LinkContentFetcher, HTMLToDocument, PromptBuilder, OpenAIGenerator). Isso dá ao usuário controle total sobre o comportamento de cada componente.\n",
    "- **Conexões Explícitas**: O código faz uso do método connect() para definir explicitamente como os dados fluem entre os componentes da pipeline. Isso oferece clareza sobre como as informações são processadas e transformadas ao longo da pipeline.\n",
    "- **Template de Prompt Customizado**: Utiliza um template personalizado para construir o prompt enviado ao modelo de linguagem, dando ao usuário a capacidade de influenciar diretamente a formatação do prompt e, consequentemente, a qualidade da resposta gerada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferenças\n",
    "- **Simplicidade vs. Flexibilidade**: O primeiro código é mais simples e direto, ideal para quem quer uma solução rápida e padronizada. O segundo oferece mais flexibilidade e controle, adequado para usuários que precisam de configurações específicas ou querem otimizar o processo detalhadamente.\n",
    "- **Configuração da Pipeline**: No primeiro código, a pipeline é predefinida, enquanto no segundo, o usuário constrói e configura cada componente da pipeline manualmente.\n",
    "- **Personalização do Prompt**: O segundo código permite uma personalização detalhada do prompt enviado ao modelo de linguagem, o que pode ser crucial para casos de uso específicos onde a formatação do prompt afeta significativamente a resposta gerada.\n",
    "Cada abordagem tem seus benefícios e escolher entre elas depende das necessidades específicas do projeto e da preferência do desenvolvedor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
