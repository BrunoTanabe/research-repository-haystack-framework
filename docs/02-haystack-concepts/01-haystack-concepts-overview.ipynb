{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haystack Concepts Overview\n",
    "\n",
    "O Haystack fornece todas as ferramentas necessárias para construir pipelines RAG personalizados com LLMs que funcionem para cada caso de uso. Isso inclui tudo, desde a prototipagem, passando pela anotação de dados, até a implantação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Components\n",
    "\n",
    "O Haystack oferece vários components, cada um executando diferentes tipos de tarefas. É possível ver toda a variedade na seção [PIPELINE COMPONENTS](https://docs.haystack.deepset.ai/docs/intro). Muitas vezes, eles são alimentados pelos mais recentes Large Language Models (LLMs) e modelos transformers. Em termos de código, são classes Python com métodos que podem chamar diretamente. Geralmente, tudo o que você precisa fazer é inicializar o componente com os parâmetros necessários e depois executá-lo com o método run().\n",
    "\n",
    "Trabalhar neste nível com os components Haystack é uma abordagem prática. Os componenes definirão o nome e o tipo de todas as suas entradas e saídas. O Component API reduzirá a complexidade e facilitará a criação de components personalizados, por exemplo, para APIs e bancos de dados de terceiros. O Haystack validará as conexões entre os components antes de executar o pipeline e, se necessário, gerará mensagens de erro com instruções sobre como corrigir os erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generators\n",
    "\n",
    "Os [generators](https://docs.haystack.deepset.ai/docs/generators) são responsáveis ​​por gerar respostas de texto após receber uma solicitação. Eles são específicos para cada tecnologia LLM (OpenAI, Cohere, modelos locais e outros). Existem dois tipos de Geradores: chat e não chat:\n",
    "\n",
    "- Os de chat permitem a conclusão do chat e são projetados para contextos de conversação. Espera uma lista de mensagens para interagir com o usuário.\n",
    "- Os Geradores sem bate-papo usam LLMs para geração de texto mais simples (por exemplo, tradução ou resumo de texto).\n",
    "\n",
    "Mais informações sobre os tipos de [generators](https://docs.haystack.deepset.ai/docs/choosing-the-right-generator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrivers\n",
    "\n",
    "Os [retrivers](https://docs.haystack.deepset.ai/docs/retrievers) examinam todos os documentos em um armazenamento de documentos, selecionam aqueles que correspondem à consulta do usuário e os passam para o próximo componente. Existem vários Retrievers customizados para armazenamentos de documentos específicos. Isso significa que eles podem lidar com requisitos específicos para cada banco de dados usando parâmetros personalizados.\n",
    "\n",
    "Por exemplo, para o Elasticsearch Document Store, É possível encontrar os pacotes Document Store e Retriever em seu [repositório GitHub](https://github.com/deepset-ai/haystack-core-integrations/tree/main/integrations/elasticsearch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document Stores\n",
    "\n",
    "O [Document Store](https://docs.haystack.deepset.ai/docs/document-store) é um objeto que armazena seus documentos no Haystack, como uma interface para um banco de dados de armazenamento. Ele usa funções específicas como write_documents() ou delete_documents() para trabalhar com dados. Vários _components_ têm acesso ao Document Store e podem interagir com ele, por exemplo, lendo ou gravando Documentos.\n",
    "\n",
    "Em caso de pipelines mais complexos no Haystack, é possível usar o DocumentWriter _component_ para gravar dados em armazenamentos de documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Classes\n",
    "\n",
    "É possível utilizar diferentes [Data Classes (classes de dados)](https://docs.haystack.deepset.ai/docs/data-classes) no Haystack para transportar os dados pelo sistema. É mais provável que as classes de dados apareçam como entradas ou saídas nas pipelines.\n",
    "\n",
    "**_Document_** class contém informações a serem transportadas pelo Pipeline. Podem ser texto, metadados, tabelas ou dados binários. Os documentos podem ser gravados em armazenamentos de documentos, mas também gravados e lidos por outros componentes.\n",
    "\n",
    "**_Answer_** class contém não apenas a resposta gerada em um Pipeline, mas também a consulta e os metadados de origem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipelines\n",
    "\n",
    "Finalmente,é possível combinar vários _components_, _document stores_ e integrações em [Pipelines](https://docs.haystack.deepset.ai/docs/pipelines) para criar sistemas poderosos e personalizáveis. É um sistema altamente flexível que permite fluxos simultâneos, componentes autônomos, loops e outros tipos de conexões. É possível ter as etapas de pré-processamento, indexação e consulta em um único pipeline ou pode dividi-las de acordo com suas necessidades.\n",
    "\n",
    "Para reutilizar Pipelines, pode salvá-los em um formato conveniente (YAML, TOML, entre outros) em um disco ou compartilhá-los usando o [processo de serialização](https://docs.haystack.deepset.ai/docs/pipelines)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
